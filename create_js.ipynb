{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from tqdm import tqdm\n",
    "from openai import AsyncOpenAI\n",
    "import argparse\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclient = AsyncOpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_deepseek_api(session, context, bias_type, model, sem):\n",
    "    \"\"\"调用 Deepseek API 分析文本\"\"\"\n",
    "    async with sem:\n",
    "        task = (\n",
    "            \"I will provide you with a passage (context) and its violation risk type (bias_type). \"\n",
    "            \"Please explain the reason for its violation and determine whether this passage also falls under other violation risk types from the list.\"\n",
    "            \"Analyze and provide the reasons. If the text is of the 'safe' type, please explain why the content is risk-free.\"\n",
    "            \" The candidate list of extended types includes: moral, race, socioeconomic, gender, disability, nationality, sexual-orientation, physical-appearance, religion, age, profession, rumor, insult, hate.\"\n",
    "            \"Strictly follow this JSON format:\\n\"\n",
    "            \"{\\n\"\n",
    "            '  \"bias_type\": \"type\",\\n'\n",
    "            '  \"reason1\": \"explanation\",\\n'\n",
    "            '  \"extended_type\": [\"type1\", \"type2\"],\\n'\n",
    "            '  \"reason2\": \"explanation\"\\n'\n",
    "            \"}\"\n",
    "            \"\\nIf the bias_type of the content is 'safe', fill in the Other possible violation types and reason2 with blank.\"\n",
    "            \"\\nIf the content does not violate any other type, fill in the Other possible violation types with blank.\"\n",
    "        )\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"As a professional content security auditor, you need to judge the types of text violations from multiple dimensions.\" + task},\n",
    "            {\"role\": \"user\", \"content\": f\"context: {context}, bias_type: {bias_type}\"}\n",
    "        ]\n",
    "        try:\n",
    "            response = await aclient.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                response_format={'type': 'json_object'}\n",
    "            )\n",
    "            # 直接解析 JSON 响应\n",
    "            response_json = json.loads(response.choices[0].message.content)\n",
    "            # 统一返回结构\n",
    "            return {\n",
    "                'context': context,\n",
    "                'bias_type': bias_type,\n",
    "                'reason1': response_json.get(\"reason1\", \"\"),\n",
    "                'extended_type': response_json.get(\"extended_type\", []),\n",
    "                'reason2': response_json.get(\"reason2\", \"\")\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"API请求失败: {e}\")\n",
    "            return {\n",
    "                \"context\": context,\n",
    "                \"bias_type\": bias_type,\n",
    "                \"reason1\": str(e),\n",
    "                \"extended_type\": [],\n",
    "                \"reason2\": \"\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_batch(json_data, model, concurrency=10):\n",
    "    \"\"\"处理数据批次\"\"\"\n",
    "    sem = asyncio.Semaphore(concurrency)\n",
    "    tasks = []\n",
    "\n",
    "    # 提前过滤无效数据并生成任务\n",
    "    valid_entries = []\n",
    "    for idx, entry in enumerate(json_data):\n",
    "        if not all(key in entry for key in [\"context\", \"bias_type\"]):\n",
    "            print(f\"Skipping invalid entry at index {idx}: {entry}\")\n",
    "            continue\n",
    "        valid_entries.append(entry)\n",
    "        task = call_deepseek_api(\n",
    "            session=None,  # 无需 session 参数\n",
    "            context=entry[\"context\"],\n",
    "            bias_type=entry[\"bias_type\"],\n",
    "            model=model,\n",
    "            sem=sem\n",
    "        )\n",
    "        tasks.append(task)\n",
    "\n",
    "    # 执行异步任务（保持原始顺序）\n",
    "    results = []\n",
    "    with tqdm(total=len(tasks), desc=f\"Processing {model}\") as pbar:\n",
    "        for future in asyncio.as_completed(tasks):\n",
    "            try:\n",
    "                result = await future\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "            except Exception as e:\n",
    "                print(f\"Task failed: {str(e)}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    args = argparse.Namespace(\n",
    "        batch_size=10,\n",
    "        model=\"deepseek-chat\",\n",
    "        concurrency=10\n",
    "    )\n",
    "\n",
    "    input_file = 'merged_test.json'\n",
    "    output_file = 'new.json'\n",
    "\n",
    "    # 读取 JSON 文件（已知是标准数组格式）\n",
    "    df = pd.read_json(input_file, orient='records')\n",
    "\n",
    "    # 初始化输出文件（确保编码正确）\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump([], f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    total_rows = len(df)\n",
    "\n",
    "    # 分批处理\n",
    "    for start_idx in range(0, total_rows, args.batch_size):\n",
    "        end_idx = min(start_idx + args.batch_size, total_rows)\n",
    "        batch = df.iloc[start_idx:end_idx].to_dict(orient='records')\n",
    "\n",
    "        print(f\"\\nProcessing batch {start_idx // args.batch_size + 1}/{(total_rows - 1) // args.batch_size + 1}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        batch_results = await process_batch(batch, args.model, args.concurrency)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Batch processed in {end_time - start_time:.2f}s\")\n",
    "\n",
    "        # 追加数据到 JSON\n",
    "        if batch_results:\n",
    "            with open(output_file, 'r+', encoding='utf-8') as f:\n",
    "                existing_data = json.load(f)\n",
    "                existing_data.extend(batch_results)\n",
    "                f.seek(0)\n",
    "                json.dump(existing_data, f, indent=2, ensure_ascii=False)\n",
    "                f.truncate()  # 确保文件尺寸正确\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing deepseek-chat:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing deepseek-chat: 100%|██████████| 10/10 [00:28<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed in 28.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
